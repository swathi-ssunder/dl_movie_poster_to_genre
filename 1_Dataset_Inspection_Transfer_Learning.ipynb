{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing required packages to be used in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generic\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Data analysis and computing\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer \n",
    "import random\n",
    "import json\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Image Processing\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "# Visualisation\n",
    "# Note: Uncomment to use the notebook as python script\n",
    "#### import matplotlib\n",
    "#### matplotlib.use('Agg')\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision.models as models\n",
    "from torch.nn.modules import CrossEntropyLoss, L1Loss\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declaration of constants to be used in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declarations related to data and file paths\n",
    "DATA_PATH = 'datasets/'\n",
    "MOVIE_POSTERS_PATH = DATA_PATH + 'posters/'\n",
    "MOVIE_GENRE_FILE = DATA_PATH + 'MovieGenre.csv'\n",
    "TARGET_PATH = 'output/model1/'\n",
    "\n",
    "# Configurations related to training\n",
    "DATASET_SIZE = 15000\n",
    "AUGMENT_RATIO = None       # Set AUGMENT_RATIO to None to have no augmentation\n",
    "TRAINING_SET_PROPORTION = 0.80\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0042234\n",
    "WEIGHT_DECAY = 0.00001\n",
    "NUM_EPOCHS = 2\n",
    "DECAY_EPOCHS = 200\n",
    "MOMENTUM = 0.9\n",
    "L2_REGULARIZATION = 0.01\n",
    "\n",
    "# Image dimensions\n",
    "WIDTH = 64\n",
    "HEIGHT = 64\n",
    "CHANNELS = 3\n",
    "\n",
    "# GPU-related configurations \n",
    "USE_GPU = torch.cuda.is_available()\n",
    "GPUS = [0, 1, 2]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if USE_GPU:\n",
    "    torch.cuda.set_device(GPUS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions for image processing\n",
    "\n",
    "toImage = transforms.ToPILImage()\n",
    "\n",
    "preprocessFn = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Movie Genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Movie Genre file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open(MOVIE_GENRE_FILE, 'r', encoding='latin1') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first few entries to inspect the structure of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe from the data, using the entries at the first index as the column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = data.pop(0)\n",
    "\n",
    "columns = list(map(lambda x: x.lower().replace(' ', '_'), columns))\n",
    "movie_genre_df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('movie_genre_df.shape', movie_genre_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the movie genre dataset to only contain relevant samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "movie_genre_df.drop_duplicates(inplace=True)\n",
    "# Drop those samples that do not have an associated genre\n",
    "movie_genre_df.drop(movie_genre_df[movie_genre_df['genre'] == ''].index, inplace=True)\n",
    "# Drop those samples that do not have an associated poster\n",
    "movie_genre_df.drop(movie_genre_df[movie_genre_df['poster'] == ''].index, inplace=True)\n",
    "# Reset the indices on the dataframe\n",
    "movie_genre_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('movie_genre_df.shape', movie_genre_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_genre_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the dataframe so that genres can be accessed easily further on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split genre to create a list of values \n",
    "movie_genre_df['genre'] = movie_genre_df['genre'].apply(lambda x: x.split('|'))\n",
    "\n",
    "# Expand genre into its own dataframe\n",
    "tags = movie_genre_df['genre'].apply(pd.Series).fillna('')\n",
    "\n",
    "# Rename the columns\n",
    "tags = tags.rename(columns = lambda x : 'genre_' + str(x))\n",
    "\n",
    "# Merge the genre dataframe back into the original dataframe\n",
    "movie_genre_df = pd.concat([movie_genre_df[:], tags[:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('movie_genre_df.shape', movie_genre_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_genre_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the distribution of unique genres across all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get distribution of unique values from multiple genre columns\n",
    "# Remove the entry representing no genre\n",
    "# Get combined counts of unique genres\n",
    "\n",
    "genre_distribution = movie_genre_df[['genre_0', 'genre_1', 'genre_2']] \\\n",
    "            .apply(lambda s: s.value_counts()) \\\n",
    "            .drop('') \\\n",
    "            .sum(axis=1) \\\n",
    "            .reset_index()\n",
    "                \n",
    "# Rename the columns acordingly                \n",
    "genre_distribution.columns = ['genre', 'count']\n",
    "\n",
    "# Sort the dataframe to order by predominant genres \n",
    "genre_distribution = genre_distribution.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Store the unique genres as a dictionary\n",
    "unique_genres = genre_distribution['genre'].tolist()\n",
    "unique_genres = {x: i for (i,x) in enumerate(unique_genres)}\n",
    "\n",
    "multi_label_binarizer = MultiLabelBinarizer(list(unique_genres.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the distribution of genres across movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genres_count = genre_distribution.shape[0]\n",
    "colors = cm.rainbow(np.linspace(0, 1, genres_count))\n",
    "\n",
    "\n",
    "plot = genre_distribution.plot(x='genre', y='count', kind='bar', width=0.8, rot=0, figsize=(15,6), \n",
    "                               color=colors, legend=None)\n",
    "\n",
    "plot.set_title('Movie Genres', fontweight='bold')\n",
    "\n",
    "plot.set_ylabel('Count of Movies')\n",
    "plot.set_xlabel('Movie Genre')\n",
    "\n",
    "plot.set_xticklabels(labels=genre_distribution['genre'], rotation=30)\n",
    "\n",
    "rects = plot.patches\n",
    "\n",
    "# Now make some labels\n",
    "labels = [int(genre_distribution['count'][i]) for i in range(len(rects))]\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    plot.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plot.get_figure() #.save_fig('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('movie_genre_df.shape', movie_genre_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark the movies that need to be augmented as they belong to minority classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fetch those genres that consist of fewer then X(say 10000) samples\n",
    "genres_partial = set(genre_distribution[genre_distribution['count'] < 10000]['genre'].tolist())\n",
    "# Label the movies based on their genres\n",
    "movie_genre_df['no_augment'] = movie_genre_df['genre'].apply(lambda x: bool(set(x) - genres_partial))\n",
    "\n",
    "augment_movie_genre_df = (movie_genre_df[movie_genre_df['no_augment'] == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('augment_movie_genre_df.shape', augment_movie_genre_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get distribution of unique values from multiple genre columns\n",
    "# Remove the entry representing no genre\n",
    "# Get combined counts of unique genres\n",
    "\n",
    "augment_genre_distribution = augment_movie_genre_df[['genre_0', 'genre_1', 'genre_2']] \\\n",
    "            .apply(lambda s: s.value_counts()) \\\n",
    "            .drop('') \\\n",
    "            .sum(axis=1) \\\n",
    "            .reset_index()\n",
    "                \n",
    "# Rename the columns acordingly                \n",
    "augment_genre_distribution.columns = ['genre', 'count']\n",
    "\n",
    "# Sort the dataframe to order by predominant genres \n",
    "augment_genre_distribution = augment_genre_distribution.sort_values(by='count', ascending=False) \\\n",
    "                                    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the distribution of genres across movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genres_count = augment_genre_distribution.shape[0]\n",
    "colors = cm.rainbow(np.linspace(0, 1, genres_count))\n",
    "\n",
    "\n",
    "plot = augment_genre_distribution.plot(x='genre', y='count', kind='bar', width=0.8, rot=0, figsize=(15,6), \n",
    "                               color=colors, legend=None)\n",
    "\n",
    "plot.set_title('Movie Genres', fontweight='bold')\n",
    "\n",
    "plot.set_ylabel('Count of Movies')\n",
    "plot.set_xlabel('Movie Genre')\n",
    "\n",
    "plot.set_xticklabels(labels=augment_genre_distribution['genre'], rotation=30)\n",
    "\n",
    "rects = plot.patches\n",
    "\n",
    "# Now make some labels\n",
    "labels = [int(augment_genre_distribution['count'][i]) for i in range(len(rects))]\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    plot.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plot.get_figure() #.save_fig('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Movie Posters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of the movie posters names by traversing the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_poster_files = set(os.listdir(MOVIE_POSTERS_PATH))\n",
    "valid_movie_samples = set(movie_genre_df['imdbid'].apply(lambda x: x+'.jpg').tolist())\n",
    "augment_valid_movie_samples = set(augment_movie_genre_df['imdbid'].apply(lambda x: x+'.jpg').tolist())\n",
    "\n",
    "poster_files = valid_poster_files.intersection(valid_movie_samples)\n",
    "augment_poster_files = valid_poster_files.intersection(augment_valid_movie_samples)\n",
    "\n",
    "imdb_ids = [i.split('.')[0] for i in poster_files]\n",
    "movie_posters = [MOVIE_POSTERS_PATH + i for i in poster_files] # if os.path.getsize(MOVIE_POSTERS_PATH + i) > 0]\n",
    "\n",
    "augment_imdb_ids = [i.split('.')[0] for i in augment_poster_files]\n",
    "augment_movie_posters = [MOVIE_POSTERS_PATH + i for i in augment_poster_files]\n",
    "\n",
    "print(\"Number of movie posters =\", len(movie_posters))\n",
    "print(\"Number of augment movie posters =\", len(augment_movie_posters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a mini-batch of posters and associated genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "range_movies = list(range(len(movie_posters)))\n",
    "range_augment_movies = list(range(len(augment_movie_posters)))\n",
    "\n",
    "if AUGMENT_RATIO is None:\n",
    "    augment_sample_size = min(len(range_augment_movies), DATASET_SIZE//2)\n",
    "    sample_size = DATASET_SIZE - augment_sample_size\n",
    "else:\n",
    "    sample_size = DATASET_SIZE//AUGMENT_RATIO\n",
    "    augment_sample_size = (DATASET_SIZE - sample_size)\n",
    "    \n",
    "sample_movies = random.sample(range_movies, sample_size)\n",
    "sample_augment_movies = random.sample(range_augment_movies, augment_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mini_batch_posters = [movie_posters[i] for i in sample_movies]\n",
    "mini_batch_imdb_ids = [imdb_ids[i] for i in sample_movies]\n",
    "\n",
    "mini_batch_genres = [movie_genre_df[movie_genre_df['imdbid'] == i]['genre'].item() for i in mini_batch_imdb_ids]\n",
    "\n",
    "augment_mini_batch_posters = [augment_movie_posters[i] for i in sample_augment_movies]\n",
    "augment_mini_batch_imdb_ids = [augment_imdb_ids[i] for i in sample_augment_movies]\n",
    "\n",
    "augment_mini_batch_genres = [augment_movie_genre_df[augment_movie_genre_df['imdbid'] == i]['genre'].item() \\\n",
    "                                 for i in augment_mini_batch_imdb_ids]\n",
    "\n",
    "num_classes = len(unique_genres)\n",
    "\n",
    "print(\"Number of movie posters =\", len(mini_batch_posters))\n",
    "print(\"Number of augment movie posters =\", len(augment_mini_batch_posters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the dimensions of one of the posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Poster dimensions :\", np.array(PIL.Image.open(mini_batch_posters[0])).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = int(len(mini_batch_posters)*TRAINING_SET_PROPORTION)\n",
    "\n",
    "train_posters = mini_batch_posters[:train_size]\n",
    "test_posters = mini_batch_posters[train_size:]\n",
    "\n",
    "X_train = torch.FloatTensor(train_size, CHANNELS, HEIGHT, WIDTH).zero_()\n",
    "X_test = torch.FloatTensor(len(mini_batch_posters) - train_size, CHANNELS, HEIGHT, WIDTH).zero_()\n",
    "\n",
    "# Resize the posters as square images are nice to work with and also apply necessary pre-processing\n",
    "for i, poster in enumerate(train_posters):\n",
    "    X_train[i] = torch.from_numpy(np.transpose(np.array(PIL.Image.open(poster).resize((WIDTH,HEIGHT))).T, (0,2,1))) \\\n",
    "                        .float().unsqueeze(0)\n",
    "\n",
    "for i, poster in enumerate(test_posters):\n",
    "    X_test[i] = torch.from_numpy(np.transpose(np.array(PIL.Image.open(poster).resize((WIDTH,HEIGHT))).T, (0,2,1))) \\\n",
    "                       .float().unsqueeze(0)\n",
    "        \n",
    "y = multi_label_binarizer.fit_transform(mini_batch_genres)\n",
    "y_train = torch.from_numpy(y[:train_size])\n",
    "y_test = torch.from_numpy(y[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "augment_train_size = int(len(augment_mini_batch_posters)*TRAINING_SET_PROPORTION)\n",
    "\n",
    "augment_train_posters = augment_mini_batch_posters[:augment_train_size]\n",
    "augment_test_posters = augment_mini_batch_posters[augment_train_size:]\n",
    "\n",
    "augment_X_train = torch.FloatTensor(augment_train_size, CHANNELS, HEIGHT, WIDTH).zero_()\n",
    "augment_X_test = torch.FloatTensor(len(augment_mini_batch_posters) - augment_train_size, \\\n",
    "                                   CHANNELS, HEIGHT, WIDTH).zero_()\n",
    "\n",
    "for i, poster in enumerate(augment_train_posters):\n",
    "    if AUGMENT_RATIO is None:\n",
    "        processed_image = PIL.Image.open(poster)\n",
    "    else:\n",
    "        processed_image = preprocessFn(PIL.Image.open(poster))\n",
    "    augment_X_train[i] = torch.from_numpy(np.transpose(np.array(processed_image \\\n",
    "                                            .resize((WIDTH,HEIGHT))).T, (0,2,1))).float().unsqueeze(0)\n",
    "\n",
    "for i, poster in enumerate(augment_test_posters):\n",
    "    augment_X_test[i] = torch.from_numpy(np.transpose(np.array(PIL.Image.open(poster) \\\n",
    "                                            .resize((WIDTH,HEIGHT))).T, (0,2,1))).float().unsqueeze(0)\n",
    "    \n",
    "augment_y = multi_label_binarizer.fit_transform(augment_mini_batch_genres)\n",
    "augment_y_train = torch.from_numpy(augment_y[:augment_train_size])\n",
    "augment_y_test = torch.from_numpy(augment_y[augment_train_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise few movie posters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "markup = '<table>'\n",
    "\n",
    "temp_genres = mini_batch_genres + augment_mini_batch_genres\n",
    "\n",
    "for i, poster in enumerate(mini_batch_posters + augment_mini_batch_posters):\n",
    "    if i%12 == 0:\n",
    "        markup += '</tr/><tr>'\n",
    "\n",
    "    markup += '<td><img src=' + poster +' width=\"70\" height=\"70\"/><span>' + ',\\n'.join(temp_genres[i]) + \\\n",
    "                            '</span</td>'\n",
    "    \n",
    "markup += '</table>'\n",
    "\n",
    "display(HTML(markup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = torch.cat((X_train, augment_X_train))\n",
    "X_test = torch.cat((X_test, augment_X_test))\n",
    "\n",
    "y_train = torch.cat((y_train, augment_y_train))\n",
    "y_test = torch.cat((y_test, augment_y_test))\n",
    "\n",
    "\n",
    "print(\"X_train shape: \", X_train.size())\n",
    "print(\"y_train shape: \", y_train.size())\n",
    "print(\"X_test shape: \", X_test.size())\n",
    "print(\"y_test shape: \", y_test.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tensor objects for the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(X_train, y_train)\n",
    "\n",
    "# Use weight-sampling to account for class-imbalance\n",
    "class_sample_count = [int(genre_distribution[genre_distribution['genre'] == x]['count'].values[0]) \\\n",
    "                          for x in multi_label_binarizer.classes]\n",
    "weights = (1 / torch.Tensor(class_sample_count)).double()\n",
    "sampler = data_utils.sampler.WeightedRandomSampler(weights, train_size)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)#, sampler = sampler)\n",
    "\n",
    "test = data_utils.TensorDataset(X_test, y_test)\n",
    "test_loader = data_utils.DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dataset_sizes = {'train': len(train), 'val': 0, 'test': len(test)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a custom architecture on top of the pre-trained model.\n",
    "\n",
    "Since the dataset is small, it is not a good idea to fine-tune the entire ConvNet due to overfitting concerns.\n",
    "As the dataset is very different from the ImageNet dataset, it might not be best to train the classifier from the top of the network, which contains more dataset-specific features. Instead, it might work better to train the classifier from activations somewhere earlier in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, baseName, model, freeze='all'):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "        if freeze == 'all':\n",
    "            for param in self.model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            for layer in freeze:\n",
    "                for param in getattr(self.model, layer).parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        self.model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the **train** and **test** functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exp_lr_scheduler(optimizer, epoch, init_lr=LEARNING_RATE, lr_decay_epoch=DECAY_EPOCHS):\n",
    "    \"\"\"Decay learning rate by a factor of 0.1 every lr_decay_epoch epochs.\"\"\"\n",
    "    lr = init_lr * (WEIGHT_DECAY**(epoch // lr_decay_epoch))\n",
    "\n",
    "    if epoch % lr_decay_epoch == 0:\n",
    "        print('LR is set to {}'.format(lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, lr_scheduler, num_epochs=25):\n",
    "    \n",
    "    start = time.time()\n",
    "    loss_history = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        \n",
    "        optimizer = lr_scheduler(optimizer, epoch)\n",
    "        # Set model to training mode\n",
    "        model.train(True)  \n",
    "\n",
    "        running_loss = []\n",
    "\n",
    "        # Iterate over data.\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "            if USE_GPU:\n",
    "                inputs = Variable(inputs.cuda()).float()\n",
    "                targets = Variable(targets.cuda()).float()\n",
    "            else:\n",
    "                inputs = Variable(inputs)\n",
    "                targets = Variable(targets).float()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.data[0])\n",
    "            del inputs\n",
    "            del targets\n",
    "\n",
    "        epoch_loss = np.mean(running_loss)\n",
    "        loss_history.append(epoch_loss)\n",
    "\n",
    "        print('Epoch {}/{}'.format(epoch, NUM_EPOCHS - 1), 'Training loss: {:.4f}'.format(epoch_loss))\n",
    "        print('-' * 10)\n",
    "        \n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return model, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    \n",
    "    start = time.time()\n",
    "    num_labels = []\n",
    "    num_preds = []\n",
    "    num_labels_union = []\n",
    "    preds_correct = []\n",
    "    diff_labels = []\n",
    "    target_labels = []\n",
    "    predicted_labels = []\n",
    "    data_inputs = []\n",
    "    predicted_outputs = []\n",
    "    output_targets = []\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train(False)  \n",
    "\n",
    "    # Iterate over data\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "        if USE_GPU:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            targets = Variable(targets.cuda()).float()\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "            targets = Variable(targets).float()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "            \n",
    "        for i, t in enumerate(targets.data):\n",
    "            labels = t.nonzero()[:,0].tolist()\n",
    "            \n",
    "            num_labels.append(len(labels)) \n",
    "            \n",
    "            probs = torch.exp(outputs.data[i])\n",
    "            j, preds = probs.topk(num_labels[-1])\n",
    "            \n",
    "            probs[preds] = 1\n",
    "        \n",
    "            if USE_GPU:\n",
    "                probs[torch.LongTensor(list(set(range(num_classes)) - set(preds))).cuda()] = 0\n",
    "                predicted_outputs.append(probs.cpu().numpy())\n",
    "                output_targets.append(targets.data[i].cpu().numpy())\n",
    "            else:\n",
    "                probs[torch.LongTensor(list(set(range(num_classes)) - set(preds)))] = 0\n",
    "                predicted_outputs.append(probs.numpy())\n",
    "                output_targets.append(targets.data[i].numpy())\n",
    "        \n",
    "            preds = [p for k, p in enumerate(preds) if j[k] != 0.0]\n",
    "            \n",
    "            data_inputs.append(inputs.data[i])\n",
    "            \n",
    "            target_labels.append([multi_label_binarizer.classes[i] for i in labels])\n",
    "            predicted_labels.append([multi_label_binarizer.classes[i] for i in preds])\n",
    "            \n",
    "            preds_correct.append(len(set(preds).intersection(labels))) \n",
    "            num_preds.append(len(preds))\n",
    "            num_labels_union.append(len(set(preds).union(labels)))\n",
    "            diff_labels.append(len(set(preds).symmetric_difference(labels)))\n",
    "\n",
    "        \n",
    "    total_preds_correct = sum(preds_correct)\n",
    "    total_num_labels = sum(num_labels)\n",
    "    total_num_preds = sum(num_preds)\n",
    "    \n",
    "    label_cardinality = np.mean(num_labels)\n",
    "    label_density = np.mean([i/total_num_labels for i in num_labels])\n",
    "    \n",
    "    precision = np.mean([x/num_preds[i] for i,x in enumerate(preds_correct) if num_preds[i] != 0])\n",
    "    recall = np.mean([x/num_labels[i] for i,x in enumerate(preds_correct)])\n",
    "    f1_score = (2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    jaccard_index = np.mean([x/num_labels_union[i] for i,x in enumerate(preds_correct)])\n",
    "    hamming_loss = np.mean([x/total_num_labels for i,x in enumerate(diff_labels)])\n",
    "    \n",
    "    time_elapsed = time.time() - start\n",
    "    \n",
    "    result = {\n",
    "        'label_cardinality': label_cardinality,\n",
    "        'label_density': label_density,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'jaccard_index': jaccard_index,\n",
    "        'hamming_loss': hamming_loss,\n",
    "        'total_num_labels': total_num_labels,\n",
    "        'total_num_preds': total_num_preds,\n",
    "        'total_preds_correct': total_preds_correct,\n",
    "        'target_labels': target_labels,\n",
    "        'predicted_labels': predicted_labels,\n",
    "        'output_targets': output_targets,\n",
    "        'predicted_outputs': predicted_outputs\n",
    "    }\n",
    "    print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download pretrained models and adapt them by fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet152 = models.resnet152(pretrained=True)\n",
    "inception_v3 = models.inception_v3(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "vggnet16_bn = models.vgg16_bn()\n",
    "\n",
    "pretrained_models = {\n",
    "    'resnet': {\n",
    "        'model': resnet152,\n",
    "        'freeze': ['conv1', 'bn1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3']\n",
    "    },\n",
    "#     'inception_v3': {\n",
    "#         'model': inception_v3,\n",
    "#         'freeze': 'all'\n",
    "#     },\n",
    "#     'alexnet': {\n",
    "#         'model': alexnet,\n",
    "#         'freeze': 'all'\n",
    "#     },\n",
    "#     'vggnet16_bn': {\n",
    "#         'model': vggnet16_bn,\n",
    "#         'freeze': 'all'\n",
    "#     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters required for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = pretrained_models['resnet']\n",
    "custom_model = CustomNet('resnet', base_model['model'], base_model['freeze'])\n",
    "\n",
    "# Note: Uncomment to load a saved model \n",
    "#### custom_model.load_state_dict(torch.load(TARGET_PATH + 'model.pth.tar'))\n",
    "\n",
    "if USE_GPU:\n",
    "    print('Using GPU...', torch.cuda.current_device())\n",
    "    custom_model = custom_model.cuda()\n",
    "\n",
    "print('Custom Model', custom_model)\n",
    "\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = optim.Adadelta(filter(lambda p: p.requires_grad, custom_model.model.parameters()), \\\n",
    "                          lr=LEARNING_RATE, weight_decay=L2_REGULARIZATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model, loss_history = train_model(custom_model, criterion, optimizer, exp_lr_scheduler, \\\n",
    "                                             num_epochs=NUM_EPOCHS)\n",
    "\n",
    "with open(TARGET_PATH + 'loss_history' + '.json', 'w') as fp:\n",
    "    json.dump(loss_history, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Visualise the training loss over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(0, NUM_EPOCHS), loss_history)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Loss history over epochs')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.savefig(TARGET_PATH + 'loss_curve.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use the model to get predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = test_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(result['f1_score'], result['hamming_loss'], result['jaccard_index'], result['precision'], result['recall'])\n",
    "# result['label_cardinality'], result['label_density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), TARGET_PATH + 'model.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 4. Visualize the ROC curve and compute the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = np.array(result['output_targets'])\n",
    "outputs = np.array(result['predicted_outputs'])\n",
    "\n",
    "for i in range(len(outputs)):\n",
    "    fpr, tpr, _ = roc_curve(targets[i], outputs[i])\n",
    "    \n",
    "    print('AUC=', auc(fpr, tpr))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=0.5)\n",
    "    \n",
    "    plt.title('AUC=' + str(auc(fpr, tpr)))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.savefig(TARGET_PATH + 'roc_curve.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Save the prediction results for inspection later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del result['output_targets']\n",
    "del result['predicted_outputs']\n",
    "\n",
    "with open(TARGET_PATH + 'prediction_results' + '.json', 'w') as fp:\n",
    "    json.dump(result, fp)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
